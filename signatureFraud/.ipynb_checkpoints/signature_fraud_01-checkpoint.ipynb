{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldSakpBdDHlv"
   },
   "source": [
    "**Import all Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k9fSREBDYV8k",
    "outputId": "69590d9a-7bc2-428c-b854-0b9f2545046e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-15 16:05:07.862202: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-08-15 16:05:07.862232: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load Successful\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import cv2\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import os\n",
    "print(\"Load Successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pSFo8EquDMp3"
   },
   "source": [
    "**upload zip file from local Directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74,
     "resources": {
      "http://localhost:8080/nbextensions/google.colab/files.js": {
       "data": "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",
       "headers": [
        [
         "content-type",
         "application/javascript"
        ]
       ],
       "ok": true,
       "status": 200,
       "status_text": "OK"
      }
     }
    },
    "id": "sgSSJZj1YcyN",
    "outputId": "c34c3aa2-8720-4bd8-97d7-28895dcda142"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "uploaded = files.upload()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gD8pKz1EDTC1"
   },
   "source": [
    "**Unzip the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g-Vs51mHdjd3"
   },
   "outputs": [],
   "source": [
    "!unzip Real.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "OvP21F0efVoj"
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "person_01 = os.listdir (\"/home/rafsunsheikh/Desktop/AI_agent/signatureFraud/static/Real/person_01\")\n",
    "person_02 = os.listdir (\"/home/rafsunsheikh/Desktop/AI_agent/signatureFraud/static/Real/person_02\")\n",
    "person_03 = os.listdir (\"/home/rafsunsheikh/Desktop/AI_agent/signatureFraud/static/Real/person_03\")\n",
    "person_04 = os.listdir (\"/home/rafsunsheikh/Desktop/AI_agent/signatureFraud/static/Real/person_04\")\n",
    "person_05 = os.listdir (\"/home/rafsunsheikh/Desktop/AI_agent/signatureFraud/static/Real/person_05\")\n",
    "person_06 = os.listdir (\"/home/rafsunsheikh/Desktop/AI_agent/signatureFraud/static/Real/person_06\")\n",
    "person_07 = os.listdir (\"/home/rafsunsheikh/Desktop/AI_agent/signatureFraud/static/Real/person_07\")\n",
    "person_08 = os.listdir (\"/home/rafsunsheikh/Desktop/AI_agent/signatureFraud/static/Real/person_08\")\n",
    "person_09 = os.listdir (\"/home/rafsunsheikh/Desktop/AI_agent/signatureFraud/static/Real/person_09\")\n",
    "person_10 = os.listdir (\"/home/rafsunsheikh/Desktop/AI_agent/signatureFraud/static/Real/person_10\")\n",
    "person_11 = os.listdir (\"/home/rafsunsheikh/Desktop/AI_agent/signatureFraud/static/Real/person_11\")\n",
    "person_12 = os.listdir (\"/home/rafsunsheikh/Desktop/AI_agent/signatureFraud/static/Real/person_12\")\n",
    "person_13 = os.listdir (\"/home/rafsunsheikh/Desktop/AI_agent/signatureFraud/static/Real/person_13\")\n",
    "person_14 = os.listdir (\"/home/rafsunsheikh/Desktop/AI_agent/signatureFraud/static/Real/person_14\")\n",
    "person_15 = os.listdir (\"/home/rafsunsheikh/Desktop/AI_agent/signatureFraud/static/Real/person_15\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QO8c8bdQEByg",
    "outputId": "a5506e1c-c48b-467f-8168-82fb9f4d36fb"
   },
   "outputs": [],
   "source": [
    "print(\"Number of signatures in person 01: {}\".format(len(person_01)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gnFa-4rCEZ81"
   },
   "outputs": [],
   "source": [
    "signatures = np.concatenate((person_01,person_02, person_03, person_04, person_05, person_06, person_07, person_08, person_09, \n",
    "                             person_10, person_11, person_12, person_13, person_14, person_15),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1r-qiBfpE7cC",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "signatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W_qE9y6nuFnQ"
   },
   "source": [
    "**Create Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "N51HfNQdKl3n"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import load_img,img_to_array\n",
    "dataset_dir = \"/home/rafsunsheikh/Desktop/AI_agent/signatureFraud/static/preprocessed_data\"\n",
    "image_size=224\n",
    "labels = []\n",
    "dataset = []\n",
    "def create_dataset(image_category,label):\n",
    "    for img in tqdm(image_category):\n",
    "        image_path = os.path.join(dataset_dir,img)\n",
    "        try:\n",
    "            image = cv2.imread(image_path,cv2.IMREAD_COLOR)\n",
    "            image = cv2.resize(image,(image_size,image_size))\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        dataset.append([np.array(image),np.array(label)])\n",
    "    random.shuffle(dataset)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3hoQR0KrQC0B",
    "outputId": "1c1a66b1-6409-4a05-89d7-9e242a738cf3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 573.85it/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 467.20it/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 589.95it/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 724.48it/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 529.26it/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 551.59it/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 669.46it/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 555.46it/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 541.52it/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 564.81it/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 696.75it/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 799.28it/s]\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:00<00:00, 81.29it/s]\n",
      "100%|█████████████████████████████████████████████| 5/5 [00:00<00:00, 97.85it/s]\n",
      "100%|████████████████████████████████████████████| 5/5 [00:00<00:00, 249.22it/s]\n"
     ]
    }
   ],
   "source": [
    "dataset1 = create_dataset(person_01,1)\n",
    "dataset1 = create_dataset(person_02,2)\n",
    "dataset1 = create_dataset(person_03,3)\n",
    "dataset1 = create_dataset(person_04,4)\n",
    "dataset1 = create_dataset(person_05,5)\n",
    "dataset1 = create_dataset(person_06,6)\n",
    "dataset1 = create_dataset(person_07,7)\n",
    "dataset1 = create_dataset(person_08,8)\n",
    "dataset1 = create_dataset(person_09,9)\n",
    "dataset1 = create_dataset(person_10,10)\n",
    "dataset1 = create_dataset(person_11,11)\n",
    "dataset1 = create_dataset(person_12,12)\n",
    "dataset1 = create_dataset(person_13,13)\n",
    "dataset1 = create_dataset(person_14,14)\n",
    "dataset1= create_dataset(person_15,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FNJu3DkaQZ7A",
    "outputId": "66fb4028-3d55-45f7-dd11-98e59531ac44",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WyLztFpKRv_p"
   },
   "source": [
    "**Plot the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "id": "IsJ2JLFwQcQa",
    "outputId": "13b9d0be-0c31-476a-d84a-7791ddbe6bfd"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "for i in range(10):\n",
    "    sample = random.choice(range(len(dataset)))\n",
    "    image = dataset[sample][0]\n",
    "    category = dataset[sample][1]\n",
    "    if category== 1:\n",
    "        label = \"Person 01\"\n",
    "    elif category== 2:\n",
    "        label = \"Person 02\"\n",
    "    elif category== 3:\n",
    "        label = \"Person 03\"\n",
    "    elif category== 4:\n",
    "        label = \"Person 04\"\n",
    "    elif category== 5:\n",
    "        label = \"Person 05\"\n",
    "    elif category== 6:\n",
    "        label = \"Person 06\"\n",
    "    elif category== 7:\n",
    "        label = \"Person 07\"\n",
    "    elif category== 8:\n",
    "        label = \"Person 08\"\n",
    "    elif category== 9:\n",
    "        label = \"Person 09\"\n",
    "    elif category== 10:\n",
    "        label = \"Person 10\"\n",
    "    elif category== 11:\n",
    "        label = \"Person 11\"\n",
    "    elif category== 12:\n",
    "        label = \"Person 12\"\n",
    "    elif category== 13:\n",
    "        label = \"Person 13\"\n",
    "    elif category== 14:\n",
    "        label = \"Person 14\"\n",
    "    elif category== 15:\n",
    "        label = \"Person 15\"\n",
    "    else:\n",
    "        label = \"Uncatagorized\"\n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.xlabel(label)\n",
    "plt.tight_layout()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ShvmHqICSz2n"
   },
   "source": [
    "**Dividing dataset into x(features) & y(target)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "cn9BssARRywb"
   },
   "outputs": [],
   "source": [
    "x = np.array([i[0] for i in dataset1]).reshape(-1,image_size,image_size,3)\n",
    "y = np.array([i[1] for i in dataset1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "hKcG5E1aS392"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dOCDmbmhS62Y",
    "outputId": "4fa52001-0d25-4cf9-84cb-d2ae4e932218"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((60, 224, 224, 3), (60,))\n",
      "((15, 224, 224, 3), (15,))\n"
     ]
    }
   ],
   "source": [
    "# #Dimension of the dataset\n",
    "print((x_train.shape,y_train.shape))\n",
    "# # print((x_val.shape,y_val.shape))\n",
    "print((x_test.shape,y_test.shape))\n",
    "#Dimension of the dataset\n",
    "# print((x_train1.shape,y_train1.shape))\n",
    "# # print((x_val.shape,y_val.shape))\n",
    "# print((x_test1.shape,y_test1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "y_train1=to_categorical(y_train)\n",
    "y_test1=to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train1 = x_train\n",
    "x_test1 = x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((60, 224, 224, 3), (60, 16))\n",
      "((15, 224, 224, 3), (15, 16))\n"
     ]
    }
   ],
   "source": [
    "#Dimension of the dataset\n",
    "print((x_train1.shape,y_train1.shape))\n",
    "# print((x_val.shape,y_val.shape))\n",
    "print((x_test1.shape,y_test1.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Data Augmentation\n",
    "train_generator = ImageDataGenerator(rotation_range=2, horizontal_flip=True, zoom_range=.1)\n",
    "\n",
    "test_generator = ImageDataGenerator(rotation_range=2, horizontal_flip= True, zoom_range=.1)\n",
    "\n",
    "#Fitting the augmentation defined above to the data\n",
    "train_generator.fit(x_train1)\n",
    "test_generator.fit(x_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8GyUDICib7R8"
   },
   "source": [
    "**creating model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3rjeZVReYdIX"
   },
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "vgg16_weight_path = '/home/rafsunsheikh/Desktop/AI_agent/signatureFraud/static/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "vgg = VGG16(\n",
    "    weights=vgg16_weight_path,\n",
    "    include_top=False, \n",
    "    input_shape=(224,224,3)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "It_LptvTcFeA"
   },
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uUgyMEdnd2Fw"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from keras import layers\n",
    "from tensorflow.keras.layers import Flatten,Dense\n",
    "model = Sequential()\n",
    "model.add(vgg)\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(layers.Dropout(rate=0.5))\n",
    "model.add(Dense(128, activation='sigmoid'))\n",
    "model.add(layers.Dropout(rate=0.2))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(layers.Dropout(0.1))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(16,activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "spWQfcn7d4du",
    "outputId": "e8be70a3-ae52-4457-bd2f-ab6a71ff6dee"
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ffQkpW_8d6vS"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DDAZMMC6eEjz",
    "outputId": "4d73d8d2-4ed6-44f7-b55c-da1c343e5469"
   },
   "outputs": [],
   "source": [
    "#Dimension of the dataset\n",
    "print((x_train1.shape,y_train1.shape))\n",
    "# print((x_val.shape,y_val.shape))\n",
    "print((x_test1.shape,y_test1.shape))\n",
    "# history = model.fit(x_train,y_train,batch_size=32,epochs=80,validation_data=(x_test,y_test))\n",
    "history1 = model.fit(x_train1,y_train1,batch_size=32,epochs=80,validation_data=(x_test1,y_test1))\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZ-_m3dEerH9",
    "outputId": "653b9547-a07e-44fe-dd21-bd276e4d10c5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_train, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Apuxm4awe7Uz",
    "outputId": "861bd120-d2e4-4dff-bc44-5cf63f874782"
   },
   "source": [
    "**Precision Recall F1-score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5vssmKmhe-YD",
    "outputId": "21a564f5-78a1-4ccf-a571-0573a4bf5552"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, classification_report\n",
    "print(classification_report(y_train, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "y_pred = model.predict(x_train1)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_train = np.argmax(y_train1, axis=1)\n",
    "\n",
    "acc_train=format(accuracy_score(y_pred, y_train),'.3f')\n",
    "precision_train=format(precision_score(y_train, y_pred, average='micro'),'.3f')\n",
    "recall_train=format(recall_score(y_train, y_pred, average='micro'),'.3f')\n",
    "f1_train=format(f1_score(y_train, y_pred, average='micro'),'.3f')\n",
    "\n",
    "cnf_matrix_train = confusion_matrix(y_pred, y_train)\n",
    "\n",
    "# print(cnf_matrix_train)\n",
    "\n",
    "FP = cnf_matrix_train.sum(axis=0) - np.diag(cnf_matrix_train) \n",
    "FN = cnf_matrix_train.sum(axis=1) - np.diag(cnf_matrix_train)\n",
    "TP = np.diag(cnf_matrix_train)\n",
    "TN = cnf_matrix_train.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP)\n",
    "# specificity = tn / (tn+fp)\n",
    "specificity_train = TNR\n",
    "\n",
    "\n",
    "y_test_pred = model.predict(x_test1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "y_test = np.argmax(y_test1, axis=1)\n",
    "\n",
    "acc_test=format(accuracy_score(y_test_pred, y_test),'.3f')\n",
    "precision_test=format(precision_score(y_test, y_test_pred, average='micro'),'.3f')\n",
    "recall_test=format(recall_score(y_test, y_test_pred, average='micro'),'.3f')\n",
    "f1_test=format(f1_score(y_test, y_test_pred, average='micro'),'.3f')\n",
    "cnf_matrix_test = confusion_matrix(y_test_pred, y_test)\n",
    "\n",
    "FP = cnf_matrix_test.sum(axis=0) - np.diag(cnf_matrix_test) \n",
    "FN = cnf_matrix_test.sum(axis=1) - np.diag(cnf_matrix_test)\n",
    "TP = np.diag(cnf_matrix_test)\n",
    "TN = cnf_matrix_test.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP)\n",
    "# specificity = tn / (tn+fp)\n",
    "specificity_test = TNR\n",
    "\n",
    "evaluation = pd.DataFrame({'Model': [],\n",
    "                           'Accuracy(train)':[],\n",
    "                           'Precision(train)':[],\n",
    "                           'Recall(train)':[],\n",
    "                           'F1_score(train)':[],\n",
    "                           'Specificity(train)':[],\n",
    "                           'Accuracy(test)':[],\n",
    "                           'Precision(test)':[],\n",
    "                           'Recalll(test)':[],\n",
    "                           'F1_score(test)':[],\n",
    "                           'Specificity(test)':[],\n",
    "                          })\n",
    "\n",
    "r = evaluation.shape[0]\n",
    "evaluation.loc[r] = ['VGG16',acc_train,precision_train,recall_train,f1_train,specificity_train,acc_test,precision_test,recall_test,f1_test,specificity_test]\n",
    "evaluation.sort_values(by = 'Accuracy(test)', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2O1qD9JkgKhO"
   },
   "source": [
    "**Prediction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "id": "Q06mviIkfA4W",
    "outputId": "93a32b2c-68c9-405b-ba89-1f04f815cf69"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,7))\n",
    "for i in range(10):\n",
    "    sample = random.choice(range(len(x_test)))\n",
    "    image = x_test[sample]\n",
    "    category = y_test[sample]\n",
    "    pred_category = y_pred[sample]\n",
    "    \n",
    "    if category== 1:\n",
    "        label = \"Person 01\"\n",
    "    elif category== 2:\n",
    "        label = \"Person 02\"\n",
    "    elif category== 3:\n",
    "        label = \"Person 03\"\n",
    "    elif category== 4:\n",
    "        label = \"Person 04\"\n",
    "    elif category== 5:\n",
    "        label = \"Person 05\"\n",
    "    elif category== 6:\n",
    "        label = \"Person 06\"\n",
    "    elif category== 7:\n",
    "        label = \"Person 07\"\n",
    "    elif category== 8:\n",
    "        label = \"Person 08\"\n",
    "    elif category== 9:\n",
    "        label = \"Person 09\"\n",
    "    elif category== 10:\n",
    "        label = \"Person 10\"\n",
    "    elif category== 11:\n",
    "        label = \"Person 11\"\n",
    "    elif category== 12:\n",
    "        label = \"Person 12\"\n",
    "    elif category== 13:\n",
    "        label = \"Person 13\"\n",
    "    elif category== 14:\n",
    "        label = \"Person 14\"\n",
    "    elif category== 15:\n",
    "        label = \"Person 15\"\n",
    "    else:\n",
    "        label = \"Uncatagorized\"\n",
    "        \n",
    "    if pred_category== 1:\n",
    "        pred_label = \"Person 01\"\n",
    "    elif pred_category== 2:\n",
    "        pred_label = \"Person 02\"\n",
    "    elif pred_category== 3:\n",
    "        pred_label = \"Person 03\"\n",
    "    elif pred_category== 4:\n",
    "        pred_label = \"Person 04\"\n",
    "    elif pred_category== 5:\n",
    "        pred_label = \"Person 05\"\n",
    "    elif pred_category== 6:\n",
    "        pred_label = \"Person 06\"\n",
    "    elif pred_category== 7:\n",
    "        pred_label = \"Person 07\"\n",
    "    elif pred_category== 8:\n",
    "        pred_label = \"Person 08\"\n",
    "    elif pred_category== 9:\n",
    "        pred_label = \"Person 09\"\n",
    "    elif pred_category== 10:\n",
    "        pred_label = \"Person 10\"\n",
    "    elif pred_category== 11:\n",
    "        pred_label = \"Person 11\"\n",
    "    elif pred_category== 12:\n",
    "        pred_label = \"Person 12\"\n",
    "    elif pred_category== 13:\n",
    "        pred_label = \"Person 13\"\n",
    "    elif pred_category== 14:\n",
    "        pred_label = \"Person 14\"\n",
    "    elif pred_category== 15:\n",
    "        pred_label = \"Person 15\"\n",
    "    else:\n",
    "        pred_label = \"Uncatagorized\"\n",
    "\n",
    "        \n",
    "    plt.subplot(2,5,i+1)\n",
    "    plt.imshow(image)\n",
    "    plt.xlabel(\"Actual:{}\\nPrediction:{}\".format(label,pred_label))\n",
    "plt.tight_layout() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gER_4mn9hn0U"
   },
   "source": [
    "**Plot Confusion Matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "\n",
    "    # Computing confusion matrix\n",
    "    cm = cnf_matrix_train\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "# Visualizing\n",
    "    fig, ax = plt.subplots(figsize=(7,7))\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "\n",
    "   # Rotating the tick labels and setting their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    # Looping over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "\n",
    "#Plotting the confusion matrix\n",
    "# confusion_mtx=confusion_matrix(y_true,y_pred)\n",
    "\n",
    "class_names=['person_01', 'person_02', 'person_03', 'person_04', 'person_05', 'person_06', 'person_07', 'person_08', 'person_09', 'person_10', 'person_11', 'person_12', 'person_13', 'person_14', 'person_15'] \n",
    "\n",
    "#Plotting non-normalized confusion matrix for train\n",
    "plot_confusion_matrix(y_train, y_pred, classes = class_names,  title = 'Non-Normalized VGG16 Confusion Matrix train')\n",
    "\n",
    "#Plotting normalized confusion matrix for train\n",
    "plot_confusion_matrix(y_train, y_pred, classes = class_names, normalize = True, title = 'Normalized VGG16 Confusion matrix train')\n",
    "\n",
    "\n",
    "#Plotting non-normalized confusion matrix for test\n",
    "plot_confusion_matrix(y_test, y_test_pred, classes = class_names,  title = 'Non-Normalized VGG16 Confusion Matrix test')\n",
    "\n",
    "#Plotting normalized confusion matrix test\n",
    "plot_confusion_matrix(y_test, y_test_pred, classes = class_names, normalize = True, title = 'Normalized VGG16 Confusion matrix test')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nsamples, nx, ny, nz = x_train1.shape\n",
    "print(nsamples)\n",
    "print(nx)\n",
    "print(ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Linear Kernel test: 0.6\n",
      "Accuracy Polynomial Kernel test: 0.6\n",
      "Accuracy Radial Basis Kernel test: 0.0\n",
      "Accuracy Sigmoid Kernel test: 0.0\n",
      "Accuracy Linear Kernel train: 1.0\n",
      "Accuracy Polynomial Kernel train: 1.0\n",
      "Accuracy Radial Basis Kernel train: 1.0\n",
      "Accuracy Sigmoid Kernel train: 0.08333333333333333\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "nsamples, nx, ny, nz = x_train1.shape\n",
    "x_train2 = x_train1.reshape((nsamples,nx*ny*nz))\n",
    "\n",
    "nsamples, nx, ny, nz = x_test1.shape\n",
    "x_test2 = x_test1.reshape((nsamples,nx*ny*nz))\n",
    "\n",
    "linear = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(x_train2, y_train)\n",
    "rbf = svm.SVC(kernel='rbf', gamma=1, C=1, decision_function_shape='ovo').fit(x_train2, y_train)\n",
    "poly = svm.SVC(kernel='poly', degree=3, C=1, decision_function_shape='ovo').fit(x_train2, y_train)\n",
    "sig = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(x_train2, y_train)\n",
    "\n",
    "linear_pred_train = linear.predict(x_train2)\n",
    "poly_pred_train = poly.predict(x_train2)\n",
    "rbf_pred_train = rbf.predict(x_train2)\n",
    "sig_pred_train = sig.predict(x_train2)\n",
    "\n",
    "linear_pred_test = linear.predict(x_test2)\n",
    "poly_pred_test = poly.predict(x_test2)\n",
    "rbf_pred_test = rbf.predict(x_test2)\n",
    "sig_pred_test = sig.predict(x_test2)\n",
    "\n",
    "accuracy_lin_test = linear.score(x_test2, y_test)\n",
    "accuracy_poly_test = poly.score(x_test2, y_test)\n",
    "accuracy_rbf_test = rbf.score(x_test2, y_test)\n",
    "accuracy_sig_test = sig.score(x_test2, y_test)\n",
    "\n",
    "print(\"Accuracy Linear Kernel test:\", accuracy_lin_test)\n",
    "print(\"Accuracy Polynomial Kernel test:\", accuracy_poly_test)\n",
    "print(\"Accuracy Radial Basis Kernel test:\", accuracy_rbf_test)\n",
    "print(\"Accuracy Sigmoid Kernel test:\", accuracy_sig_test)\n",
    "      \n",
    "accuracy_lin_train = linear.score(x_train2, y_train)\n",
    "accuracy_poly_train = poly.score(x_train2, y_train)\n",
    "accuracy_rbf_train = rbf.score(x_train2, y_train)\n",
    "accuracy_sig_train = sig.score(x_train2, y_train)\n",
    "\n",
    "print(\"Accuracy Linear Kernel train:\", accuracy_lin_train)\n",
    "print(\"Accuracy Polynomial Kernel train:\", accuracy_poly_train)\n",
    "print(\"Accuracy Radial Basis Kernel train:\", accuracy_rbf_train)\n",
    "print(\"Accuracy Sigmoid Kernel train:\", accuracy_sig_train)      \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10734/340904341.py:107: RuntimeWarning: invalid value encountered in true_divide\n",
      "  TPR = TP/(TP+FN)\n",
      "/tmp/ipykernel_10734/340904341.py:108: RuntimeWarning: invalid value encountered in true_divide\n",
      "  TNR = TN/(TN+FP)\n",
      "/tmp/ipykernel_10734/340904341.py:170: RuntimeWarning: invalid value encountered in true_divide\n",
      "  TPR = TP/(TP+FN)\n",
      "/tmp/ipykernel_10734/340904341.py:183: RuntimeWarning: invalid value encountered in true_divide\n",
      "  TPR = TP/(TP+FN)\n",
      "/tmp/ipykernel_10734/340904341.py:184: RuntimeWarning: invalid value encountered in true_divide\n",
      "  TNR = TN/(TN+FP)\n",
      "/tmp/ipykernel_10734/340904341.py:196: RuntimeWarning: invalid value encountered in true_divide\n",
      "  TPR = TP/(TP+FN)\n",
      "/tmp/ipykernel_10734/340904341.py:209: RuntimeWarning: invalid value encountered in true_divide\n",
      "  TPR = TP/(TP+FN)\n",
      "/tmp/ipykernel_10734/340904341.py:210: RuntimeWarning: invalid value encountered in true_divide\n",
      "  TNR = TN/(TN+FP)\n",
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy Linear (train)</th>\n",
       "      <th>Accuracy rbf (train)</th>\n",
       "      <th>Accuracy poly (train)</th>\n",
       "      <th>Accuracy sig (train)</th>\n",
       "      <th>Precision linear (train)</th>\n",
       "      <th>Precision rbf (train)</th>\n",
       "      <th>Precision poly (train)</th>\n",
       "      <th>Precision sig (train)</th>\n",
       "      <th>Recall linear (train)</th>\n",
       "      <th>...</th>\n",
       "      <th>Recalll poly (test)</th>\n",
       "      <th>Recalll sig (test)</th>\n",
       "      <th>F1_score linear (test)</th>\n",
       "      <th>F1_score rbf (test)</th>\n",
       "      <th>F1_score poly (test)</th>\n",
       "      <th>F1_score sig (test)</th>\n",
       "      <th>Specificity linear (test)</th>\n",
       "      <th>Specificity rbf (test)</th>\n",
       "      <th>Specificity poly (test)</th>\n",
       "      <th>Specificity sig (test)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.083</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.083</td>\n",
       "      <td>1.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, ...</td>\n",
       "      <td>[0.9333333333333333, 0.9333333333333333, 0.933...</td>\n",
       "      <td>[1.0, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, ...</td>\n",
       "      <td>[0.9333333333333333, 0.9333333333333333, 0.933...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Accuracy Linear (train) Accuracy rbf (train) Accuracy poly (train)  \\\n",
       "0   SVM                   1.000                1.000                 1.000   \n",
       "\n",
       "  Accuracy sig (train) Precision linear (train) Precision rbf (train)  \\\n",
       "0                0.083                    1.000                 1.000   \n",
       "\n",
       "  Precision poly (train) Precision sig (train) Recall linear (train)  ...  \\\n",
       "0                  1.000                 0.083                 1.000  ...   \n",
       "\n",
       "  Recalll poly (test) Recalll sig (test) F1_score linear (test)  \\\n",
       "0               0.600              0.000                  0.600   \n",
       "\n",
       "  F1_score rbf (test) F1_score poly (test) F1_score sig (test)  \\\n",
       "0               0.000                0.600               0.000   \n",
       "\n",
       "                           Specificity linear (test)  \\\n",
       "0  [1.0, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, ...   \n",
       "\n",
       "                              Specificity rbf (test)  \\\n",
       "0  [0.9333333333333333, 0.9333333333333333, 0.933...   \n",
       "\n",
       "                             Specificity poly (test)  \\\n",
       "0  [1.0, 1.0, 1.0, 1.0, 1.0, 0.9333333333333333, ...   \n",
       "\n",
       "                              Specificity sig (test)  \n",
       "0  [0.9333333333333333, 0.9333333333333333, 0.933...  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, accuracy_score, recall_score, f1_score, confusion_matrix# y_pred = model.predict(x_train1)\n",
    "# linear rbf poly sig\n",
    "nsamples, nx, ny, nz = x_train1.shape\n",
    "x_train2 = x_train1.reshape((nsamples,nx*ny*nz))\n",
    "\n",
    "y_pred_linear = linear.predict(x_train2)\n",
    "# y_pred_linear = np.argmax(y_pred_linear, axis=1)\n",
    "y_pred_rbf = rbf.predict(x_train2)\n",
    "# y_pred_rbf = np.argmax(y_pred_rbf, axis=1)\n",
    "y_pred_poly = poly.predict(x_train2)\n",
    "# y_pred_poly = np.argmax(y_pred_poly, axis=1)\n",
    "y_pred_sig = sig.predict(x_train2)\n",
    "# y_pred_sig = np.argmax(y_pred_sig, axis=1)\n",
    "\n",
    "y_train = np.argmax(y_train1, axis=1)\n",
    "\n",
    "\n",
    "nsamples, nx, ny, nz = x_test1.shape\n",
    "x_test2 = x_test1.reshape((nsamples,nx*ny*nz))\n",
    "\n",
    "y_test_pred_linear = linear.predict(x_test2)\n",
    "# y_test_pred_linear = np.argmax(y_test_pred_linear, axis=1)\n",
    "y_test_pred_rbf = rbf.predict(x_test2)\n",
    "# y_test_pred_rbf = np.argmax(y_test_pred_rbf, axis=1)\n",
    "y_test_pred_poly = poly.predict(x_test2)\n",
    "# y_test_pred_poly = np.argmax(y_test_pred_poly, axis=1)\n",
    "y_test_pred_sig = sig.predict(x_test2)\n",
    "# y_test_pred_sig = np.argmax(y_test_pred_sig, axis=1)\n",
    "\n",
    "y_test = np.argmax(y_test1, axis=1)\n",
    "\n",
    "acc_train_linear=format(accuracy_score(y_pred_linear, y_train),'.3f')\n",
    "acc_train_rbf=format(accuracy_score(y_pred_rbf, y_train),'.3f')\n",
    "acc_train_poly=format(accuracy_score(y_pred_poly, y_train),'.3f')\n",
    "acc_train_sig=format(accuracy_score(y_pred_sig, y_train),'.3f')\n",
    "\n",
    "precision_train_linear=format(precision_score(y_train, y_pred_linear, average='micro'),'.3f')\n",
    "precision_train_rbf=format(precision_score(y_train, y_pred_rbf, average='micro'),'.3f')\n",
    "precision_train_poly=format(precision_score(y_train, y_pred_poly, average='micro'),'.3f')\n",
    "precision_train_sig=format(precision_score(y_train, y_pred_sig, average='micro'),'.3f')\n",
    "\n",
    "recall_train_linear=format(recall_score(y_train, y_pred_linear, average='micro'),'.3f')\n",
    "recall_train_rbf=format(recall_score(y_train, y_pred_rbf, average='micro'),'.3f')\n",
    "recall_train_poly=format(recall_score(y_train, y_pred_poly, average='micro'),'.3f')\n",
    "recall_train_sig=format(recall_score(y_train, y_pred_sig, average='micro'),'.3f')\n",
    "\n",
    "f1_train_linear=format(f1_score(y_train, y_pred_linear, average='micro'),'.3f')\n",
    "f1_train_rbf=format(f1_score(y_train, y_pred_rbf, average='micro'),'.3f')\n",
    "f1_train_poly=format(f1_score(y_train, y_pred_poly, average='micro'),'.3f')\n",
    "f1_train_sig=format(f1_score(y_train, y_pred_sig, average='micro'),'.3f')\n",
    "\n",
    "cnf_matrix_train_linear = confusion_matrix(y_pred_linear, y_train)\n",
    "cnf_matrix_train_rbf = confusion_matrix(y_pred_rbf, y_train)\n",
    "cnf_matrix_train_poly = confusion_matrix(y_pred_poly, y_train)\n",
    "cnf_matrix_train_sig = confusion_matrix(y_pred_sig, y_train)\n",
    "\n",
    "# print(cnf_matrix_train)\n",
    "\n",
    "FP = cnf_matrix_train_linear.sum(axis=0) - np.diag(cnf_matrix_train_linear) \n",
    "FN = cnf_matrix_train_linear.sum(axis=1) - np.diag(cnf_matrix_train_linear)\n",
    "TP = np.diag(cnf_matrix_train_linear)\n",
    "TN = cnf_matrix_train_linear.sum() - (FP + FN + TP)\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "specificity_train_linear = TNR\n",
    "\n",
    "FP = cnf_matrix_train_rbf.sum(axis=0) - np.diag(cnf_matrix_train_rbf) \n",
    "FN = cnf_matrix_train_rbf.sum(axis=1) - np.diag(cnf_matrix_train_rbf)\n",
    "TP = np.diag(cnf_matrix_train_rbf)\n",
    "TN = cnf_matrix_train_rbf.sum() - (FP + FN + TP)\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "specificity_train_rbf = TNR\n",
    "\n",
    "FP = cnf_matrix_train_poly.sum(axis=0) - np.diag(cnf_matrix_train_poly) \n",
    "FN = cnf_matrix_train_poly.sum(axis=1) - np.diag(cnf_matrix_train_poly)\n",
    "TP = np.diag(cnf_matrix_train_poly)\n",
    "TN = cnf_matrix_train_poly.sum() - (FP + FN + TP)\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "specificity_train_poly = TNR\n",
    "\n",
    "FP = cnf_matrix_train_sig.sum(axis=0) - np.diag(cnf_matrix_train_sig) \n",
    "FN = cnf_matrix_train_sig.sum(axis=1) - np.diag(cnf_matrix_train_sig)\n",
    "TP = np.diag(cnf_matrix_train_sig)\n",
    "TN = cnf_matrix_train_sig.sum() - (FP + FN + TP)\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "specificity_train_sig = TNR\n",
    "\n",
    "acc_test_linear=format(accuracy_score(y_test_pred_linear, y_test),'.3f')\n",
    "acc_test_rbf=format(accuracy_score(y_test_pred_rbf, y_test),'.3f')\n",
    "acc_test_poly=format(accuracy_score(y_test_pred_poly, y_test),'.3f')\n",
    "acc_test_sig=format(accuracy_score(y_test_pred_sig, y_test),'.3f')\n",
    "\n",
    "precision_test_linear=format(precision_score(y_test, y_test_pred_linear, average='micro'),'.3f')\n",
    "precision_test_rbf=format(precision_score(y_test, y_test_pred_rbf, average='micro'),'.3f')\n",
    "precision_test_poly=format(precision_score(y_test, y_test_pred_poly, average='micro'),'.3f')\n",
    "precision_test_sig=format(precision_score(y_test, y_test_pred_sig, average='micro'),'.3f')\n",
    "\n",
    "recall_test_linear=format(recall_score(y_test, y_test_pred_linear, average='micro'),'.3f')\n",
    "recall_test_rbf=format(recall_score(y_test, y_test_pred_rbf, average='micro'),'.3f')\n",
    "recall_test_poly=format(recall_score(y_test, y_test_pred_poly, average='micro'),'.3f')\n",
    "recall_test_sig=format(recall_score(y_test, y_test_pred_sig, average='micro'),'.3f')\n",
    "\n",
    "f1_test_linear=format(f1_score(y_test, y_test_pred_linear, average='micro'),'.3f')\n",
    "f1_test_rbf=format(f1_score(y_test, y_test_pred_rbf, average='micro'),'.3f')\n",
    "f1_test_poly=format(f1_score(y_test, y_test_pred_poly, average='micro'),'.3f')\n",
    "f1_test_sig=format(f1_score(y_test, y_test_pred_sig, average='micro'),'.3f')\n",
    "\n",
    "cnf_matrix_test_linear = confusion_matrix(y_test_pred_linear, y_test)\n",
    "cnf_matrix_test_rbf = confusion_matrix(y_test_pred_rbf, y_test)\n",
    "cnf_matrix_test_poly = confusion_matrix(y_test_pred_poly, y_test)\n",
    "cnf_matrix_test_sig = confusion_matrix(y_test_pred_sig, y_test)\n",
    "\n",
    "FP = cnf_matrix_test_linear.sum(axis=0) - np.diag(cnf_matrix_test_linear) \n",
    "FN = cnf_matrix_test_linear.sum(axis=1) - np.diag(cnf_matrix_test_linear)\n",
    "TP = np.diag(cnf_matrix_test_linear)\n",
    "TN = cnf_matrix_test_linear.sum() - (FP + FN + TP)\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "specificity_test_linear = TNR\n",
    "\n",
    "FP = cnf_matrix_test_rbf.sum(axis=0) - np.diag(cnf_matrix_test_rbf) \n",
    "FN = cnf_matrix_test_rbf.sum(axis=1) - np.diag(cnf_matrix_test_rbf)\n",
    "TP = np.diag(cnf_matrix_test_rbf)\n",
    "TN = cnf_matrix_test_rbf.sum() - (FP + FN + TP)\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "specificity_test_rbf = TNR\n",
    "\n",
    "FP = cnf_matrix_test_poly.sum(axis=0) - np.diag(cnf_matrix_test_poly) \n",
    "FN = cnf_matrix_test_poly.sum(axis=1) - np.diag(cnf_matrix_test_poly)\n",
    "TP = np.diag(cnf_matrix_test_poly)\n",
    "TN = cnf_matrix_test_poly.sum() - (FP + FN + TP)\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "specificity_test_poly = TNR\n",
    "\n",
    "FP = cnf_matrix_test_sig.sum(axis=0) - np.diag(cnf_matrix_test_sig) \n",
    "FN = cnf_matrix_test_sig.sum(axis=1) - np.diag(cnf_matrix_test_sig)\n",
    "TP = np.diag(cnf_matrix_test_sig)\n",
    "TN = cnf_matrix_test_sig.sum() - (FP + FN + TP)\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "TNR = TN/(TN+FP)\n",
    "specificity_test_sig = TNR\n",
    "\n",
    "evaluation = pd.DataFrame({'Model': [],\n",
    "                           'Accuracy Linear (train)':[],\n",
    "                           'Accuracy rbf (train)':[],\n",
    "                           'Accuracy poly (train)':[],\n",
    "                           'Accuracy sig (train)':[],\n",
    "                           'Precision linear (train)':[],\n",
    "                           'Precision rbf (train)':[],\n",
    "                           'Precision poly (train)':[],\n",
    "                           'Precision sig (train)':[],\n",
    "                           'Recall linear (train)':[],\n",
    "                           'Recall rbf (train)':[],\n",
    "                           'Recall poly (train)':[],\n",
    "                           'Recall sig (train)':[],\n",
    "                           'F1_score linear (train)':[],\n",
    "                           'F1_score rbf (train)':[],\n",
    "                           'F1_score poly (train)':[],\n",
    "                           'F1_score sig (train)':[],\n",
    "                           'Specificity linear (train)':[],\n",
    "                           'Specificity rbf (train)':[],\n",
    "                           'Specificity poly (train)':[],\n",
    "                           'Specificity sig (train)':[],\n",
    "                           'Accuracy linear (test)':[],\n",
    "                           'Accuracy rbf (test)':[],\n",
    "                           'Accuracy poly (test)':[],\n",
    "                           'Accuracy sig (test)':[],\n",
    "                           'Precision linear (test)':[],\n",
    "                           'Precision rbf (test)':[],\n",
    "                           'Precision poly (test)':[],\n",
    "                           'Precision sig (test)':[],\n",
    "                           'Recalll linear (test)':[],\n",
    "                           'Recalll rbf (test)':[],\n",
    "                           'Recalll poly (test)':[],\n",
    "                           'Recalll sig (test)':[],\n",
    "                           'F1_score linear (test)':[],\n",
    "                           'F1_score rbf (test)':[],\n",
    "                           'F1_score poly (test)':[],\n",
    "                           'F1_score sig (test)':[],\n",
    "                           'Specificity linear (test)':[],\n",
    "                           'Specificity rbf (test)':[],\n",
    "                           'Specificity poly (test)':[],\n",
    "                           'Specificity sig (test)':[],\n",
    "                          })\n",
    "\n",
    "r = evaluation.shape[0]\n",
    "evaluation.loc[r] = ['SVM',acc_train_linear,acc_train_rbf,acc_train_poly,acc_train_sig,precision_train_linear,precision_train_rbf,precision_train_poly,precision_train_sig,recall_train_linear,recall_train_rbf,recall_train_poly,recall_train_sig,f1_train_linear,f1_train_rbf,f1_train_poly,f1_train_sig,specificity_train_linear,specificity_train_rbf,specificity_train_poly,specificity_train_sig,acc_test_linear,acc_test_rbf,acc_test_poly,acc_test_sig,precision_test_linear,precision_test_rbf,precision_test_poly,precision_test_sig,recall_test_linear,recall_test_rbf,recall_test_poly,recall_test_sig,f1_test_linear,f1_test_rbf,f1_test_poly,f1_test_sig,specificity_test_linear,specificity_test_rbf,specificity_test_poly,specificity_test_sig]\n",
    "evaluation.sort_values(by = 'Accuracy linear (test)', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=10, random_state=500)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf =RandomForestClassifier(n_estimators=10, random_state=500)\n",
    "nsamples, nx, ny, nz = x_train1.shape\n",
    "x_train2 = x_train1.reshape((nsamples,nx*ny*nz))\n",
    "\n",
    "nsamples, nx, ny, nz = x_test1.shape\n",
    "x_test2 = x_test1.reshape((nsamples,nx*ny*nz))\n",
    "\n",
    "clf.fit(x_train2, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of RFC train:\n",
      "\n",
      "[[0 1 0 1 3 2 0 2 1 1 0 0 1 0 0 0]\n",
      " [0 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 4 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 3 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 2 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 2 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 4 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 3 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 2 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 3 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 4 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 3 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 4 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3]]\n",
      "Confusion Matrix of RFC test:\n",
      "\n",
      "[[0 1 1 1 1 1 2 1 1 1 1 1 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1495: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1495: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "/tmp/ipykernel_10734/2443821893.py:67: RuntimeWarning: invalid value encountered in true_divide\n",
      "  TPR = TP/(TP+FN)\n",
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(train)</th>\n",
       "      <th>Precision(train)</th>\n",
       "      <th>Recall(train)</th>\n",
       "      <th>F1_score(train)</th>\n",
       "      <th>Specificity(train)</th>\n",
       "      <th>Accuracy(test)</th>\n",
       "      <th>Precision(test)</th>\n",
       "      <th>Recalll(test)</th>\n",
       "      <th>F1_score(test)</th>\n",
       "      <th>Specificity(test)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RFC</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.938</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.826</td>\n",
       "      <td>[1.0, 0.9824561403508771, 1.0, 0.9824561403508...</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.062</td>\n",
       "      <td>[1.0, 0.9333333333333333, 0.9333333333333333, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Accuracy(train) Precision(train) Recall(train) F1_score(train)  \\\n",
       "0   RFC           0.800            0.938         0.760           0.826   \n",
       "\n",
       "                                  Specificity(train) Accuracy(test)  \\\n",
       "0  [1.0, 0.9824561403508771, 1.0, 0.9824561403508...          0.067   \n",
       "\n",
       "  Precision(test) Recalll(test) F1_score(test)  \\\n",
       "0           0.062         0.062          0.062   \n",
       "\n",
       "                                   Specificity(test)  \n",
       "0  [1.0, 0.9333333333333333, 0.9333333333333333, ...  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_train=format(accuracy_score(clf.predict(x_train2), y_train1),'.3f')\n",
    "precision_train=format(precision_score(y_train1, clf.predict(x_train2), average='macro'),'.3f')\n",
    "recall_train=format(recall_score(y_train1,clf.predict(x_train2), average='macro'),'.3f')\n",
    "f1_train=format(f1_score(y_train1,clf.predict(x_train2), average='macro'),'.3f')\n",
    "\n",
    "y_pred = clf.predict(x_train2)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_train = np.argmax(y_train1, axis=1)\n",
    "\n",
    "# y_test_pred = model.predict(x_test1)\n",
    "# y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "# y_test = np.argmax(y_test1, axis=1)\n",
    "\n",
    "\n",
    "cnf_matrix_train = confusion_matrix(y_pred, y_train)\n",
    "print(\"Confusion Matrix of RFC train:\\n\")\n",
    "print(cnf_matrix_train)\n",
    "\n",
    "FP = cnf_matrix_train.sum(axis=0) - np.diag(cnf_matrix_train) \n",
    "FN = cnf_matrix_train.sum(axis=1) - np.diag(cnf_matrix_train)\n",
    "TP = np.diag(cnf_matrix_train)\n",
    "TN = cnf_matrix_train.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP)\n",
    "# specificity = tn / (tn+fp)\n",
    "specificity_train = TNR\n",
    "\n",
    "\n",
    "acc_test=format(accuracy_score(clf.predict(x_test2), y_test1),'.3f')\n",
    "precision_test=format(precision_score(y_test1, clf.predict(x_test2), average='macro'),'.3f')\n",
    "recall_test=format(recall_score(y_test1, clf.predict(x_test2), average='macro'),'.3f')\n",
    "f1_test=format(f1_score(y_test1, clf.predict(x_test2), average='macro'),'.3f')\n",
    "\n",
    "# y_pred = clf.predict(x_train2)\n",
    "# y_pred = np.argmax(y_pred, axis=1)\n",
    "# y_train = np.argmax(y_train1, axis=1)\n",
    "\n",
    "y_test_pred = clf.predict(x_test2)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "y_test = np.argmax(y_test1, axis=1)\n",
    "\n",
    "\n",
    "cnf_matrix_test = confusion_matrix(y_test_pred, y_test)\n",
    "print(\"Confusion Matrix of RFC test:\\n\")\n",
    "print(cnf_matrix_test)\n",
    "# print(cnf_matrix_train)\n",
    "\n",
    "FP = cnf_matrix_test.sum(axis=0) - np.diag(cnf_matrix_test) \n",
    "FN = cnf_matrix_test.sum(axis=1) - np.diag(cnf_matrix_test)\n",
    "TP = np.diag(cnf_matrix_test)\n",
    "TN = cnf_matrix_test.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP)\n",
    "# specificity = tn / (tn+fp)\n",
    "specificity_test = TNR\n",
    "\n",
    "evaluation = pd.DataFrame({'Model': [],\n",
    "                           'Accuracy(train)':[],\n",
    "                           'Precision(train)':[],\n",
    "                           'Recall(train)':[],\n",
    "                           'F1_score(train)':[],\n",
    "                           'Specificity(train)':[],\n",
    "                           'Accuracy(test)':[],\n",
    "                           'Precision(test)':[],\n",
    "                           'Recalll(test)':[],\n",
    "                           'F1_score(test)':[],\n",
    "                           'Specificity(test)':[],\n",
    "                          })\n",
    "\n",
    "r = evaluation.shape[0]\n",
    "evaluation.loc[r] = ['RFC',acc_train,precision_train,recall_train,f1_train,specificity_train,acc_test,precision_test,recall_test,f1_test,specificity_test]\n",
    "evaluation.sort_values(by = 'Accuracy(test)', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf=KNeighborsClassifier()\n",
    "\n",
    "nsamples, nx, ny, nz = x_train1.shape\n",
    "x_train2 = x_train1.reshape((nsamples,nx*ny*nz))\n",
    "\n",
    "nsamples, nx, ny, nz = x_test1.shape\n",
    "x_test2 = x_test1.reshape((nsamples,nx*ny*nz))\n",
    "\n",
    "knn_clf.fit(x_train2,y_train1)\n",
    "# ypred=knn_clf.predict(X_test) #These are the predicted output values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1495: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of KNN train:\n",
      "\n",
      "[[0 0 1 1 2 3 0 0 1 3 0 3 4 3 3 2]\n",
      " [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 3 2 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 2 0 0 0 0 0 0 0 0 0]\n",
      " [0 3 0 0 0 0 2 5 1 0 0 1 0 1 1 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 4 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10734/1855606426.py:31: RuntimeWarning: invalid value encountered in true_divide\n",
      "  TPR = TP/(TP+FN)\n",
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1495: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "/tmp/ipykernel_10734/1855606426.py:68: RuntimeWarning: invalid value encountered in true_divide\n",
      "  TPR = TP/(TP+FN)\n",
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of KNN test:\n",
      "\n",
      "[[0 1 1 0 0 0 0 1 0 0 0 1 1 0 2]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 1 0 1 1 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(train)</th>\n",
       "      <th>Precision(train)</th>\n",
       "      <th>Recall(train)</th>\n",
       "      <th>F1_score(train)</th>\n",
       "      <th>Specificity(train)</th>\n",
       "      <th>Accuracy(test)</th>\n",
       "      <th>Precision(test)</th>\n",
       "      <th>Recalll(test)</th>\n",
       "      <th>F1_score(test)</th>\n",
       "      <th>Specificity(test)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.549</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.340</td>\n",
       "      <td>[1.0, 0.9491525423728814, 0.9655172413793104, ...</td>\n",
       "      <td>0.267</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0.250</td>\n",
       "      <td>[1.0, 0.9333333333333333, 0.9333333333333333, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Accuracy(train) Precision(train) Recall(train) F1_score(train)  \\\n",
       "0   KNN           0.350            0.549         0.315           0.340   \n",
       "\n",
       "                                  Specificity(train) Accuracy(test)  \\\n",
       "0  [1.0, 0.9491525423728814, 0.9655172413793104, ...          0.267   \n",
       "\n",
       "  Precision(test) Recalll(test) F1_score(test)  \\\n",
       "0           0.250         0.250          0.250   \n",
       "\n",
       "                                   Specificity(test)  \n",
       "0  [1.0, 0.9333333333333333, 0.9333333333333333, ...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_train=format(accuracy_score(knn_clf.predict(x_train2), y_train1),'.3f')\n",
    "precision_train=format(precision_score(y_train1, knn_clf.predict(x_train2), average='macro'),'.3f')\n",
    "recall_train=format(recall_score(y_train1, knn_clf.predict(x_train2), average='macro'),'.3f')\n",
    "f1_train=format(f1_score(y_train1, knn_clf.predict(x_train2), average='macro'),'.3f')\n",
    "\n",
    "y_pred = knn_clf.predict(x_train2)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_train = np.argmax(y_train1, axis=1)\n",
    "\n",
    "# y_test_pred = model.predict(x_test1)\n",
    "# y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "# y_test = np.argmax(y_test1, axis=1)\n",
    "\n",
    "\n",
    "cnf_matrix_train = confusion_matrix(y_pred, y_train)\n",
    "print(\"Confusion Matrix of KNN train:\\n\")\n",
    "print(cnf_matrix_train)\n",
    "# print(cnf_matrix_train)\n",
    "\n",
    "FP = cnf_matrix_train.sum(axis=0) - np.diag(cnf_matrix_train) \n",
    "FN = cnf_matrix_train.sum(axis=1) - np.diag(cnf_matrix_train)\n",
    "TP = np.diag(cnf_matrix_train)\n",
    "TN = cnf_matrix_train.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP)\n",
    "# specificity = tn / (tn+fp)\n",
    "specificity_train = TNR\n",
    "\n",
    "\n",
    "acc_test=format(accuracy_score(knn_clf.predict(x_test2), y_test1),'.3f')\n",
    "precision_test=format(precision_score(y_test1, knn_clf.predict(x_test2), average='macro'),'.3f')\n",
    "recall_test=format(recall_score(y_test1, knn_clf.predict(x_test2), average='macro'),'.3f')\n",
    "f1_test=format(f1_score(y_test1, knn_clf.predict(x_test2), average='macro'),'.3f')\n",
    "\n",
    "# y_pred = clf.predict(x_train2)\n",
    "# y_pred = np.argmax(y_pred, axis=1)\n",
    "# y_train = np.argmax(y_train1, axis=1)\n",
    "\n",
    "y_test_pred = knn_clf.predict(x_test2)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "y_test = np.argmax(y_test1, axis=1)\n",
    "\n",
    "\n",
    "cnf_matrix_test = confusion_matrix(y_test_pred, y_test)\n",
    "print(\"Confusion Matrix of KNN test:\\n\")\n",
    "print(cnf_matrix_test)\n",
    "# print(cnf_matrix_train)\n",
    "\n",
    "FP = cnf_matrix_test.sum(axis=0) - np.diag(cnf_matrix_test) \n",
    "FN = cnf_matrix_test.sum(axis=1) - np.diag(cnf_matrix_test)\n",
    "TP = np.diag(cnf_matrix_test)\n",
    "TN = cnf_matrix_test.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP)\n",
    "# specificity = tn / (tn+fp)\n",
    "specificity_test = TNR\n",
    "\n",
    "evaluation = pd.DataFrame({'Model': [],\n",
    "                           'Accuracy(train)':[],\n",
    "                           'Precision(train)':[],\n",
    "                           'Recall(train)':[],\n",
    "                           'F1_score(train)':[],\n",
    "                           'Specificity(train)':[],\n",
    "                           'Accuracy(test)':[],\n",
    "                           'Precision(test)':[],\n",
    "                           'Recalll(test)':[],\n",
    "                           'F1_score(test)':[],\n",
    "                           'Specificity(test)':[],\n",
    "                          })\n",
    "\n",
    "r = evaluation.shape[0]\n",
    "evaluation.loc[r] = ['KNN',acc_train,precision_train,recall_train,f1_train,specificity_train,acc_test,precision_test,recall_test,f1_test,specificity_test]\n",
    "evaluation.sort_values(by = 'Accuracy(test)', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decision Tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=3, min_samples_leaf=5, random_state=100)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt_clf = DecisionTreeClassifier(criterion = \"gini\", random_state = 100, max_depth=3, min_samples_leaf=5)\n",
    "nsamples, nx, ny, nz = x_train1.shape\n",
    "x_train2 = x_train1.reshape((nsamples,nx*ny*nz))\n",
    "\n",
    "nsamples, nx, ny, nz = x_test1.shape\n",
    "x_test2 = x_test1.reshape((nsamples,nx*ny*nz))\n",
    "\n",
    "dt_clf.fit(x_train2, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix of DT train:\n",
      "\n",
      "[[0 4 4 4 0 4 4 0 3 4 4 4 4 4 4 3]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 5 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 5 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "Confusion Matrix of DT test:\n",
      "\n",
      "[[0 1 0 1 0 1 1 0 2 1 0 1 0 1 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1495: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "/tmp/ipykernel_10734/1703208588.py:31: RuntimeWarning: invalid value encountered in true_divide\n",
      "  TPR = TP/(TP+FN)\n",
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/sklearn/metrics/_classification.py:1495: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(\n",
      "/tmp/ipykernel_10734/1703208588.py:68: RuntimeWarning: invalid value encountered in true_divide\n",
      "  TPR = TP/(TP+FN)\n",
      "/home/rafsunsheikh/Desktop/AI_agent/env/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return array(a, dtype, copy=False, order=order)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy(train)</th>\n",
       "      <th>Precision(train)</th>\n",
       "      <th>Recall(train)</th>\n",
       "      <th>F1_score(train)</th>\n",
       "      <th>Specificity(train)</th>\n",
       "      <th>Accuracy(test)</th>\n",
       "      <th>Precision(test)</th>\n",
       "      <th>Recalll(test)</th>\n",
       "      <th>F1_score(test)</th>\n",
       "      <th>Specificity(test)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.125</td>\n",
       "      <td>[1.0, 0.9333333333333333, 0.9333333333333333, ...</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[1.0, 0.9333333333333333, 0.9333333333333333, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model Accuracy(train) Precision(train) Recall(train) F1_score(train)  \\\n",
       "0    DT           0.167            0.125         0.125           0.125   \n",
       "\n",
       "                                  Specificity(train) Accuracy(test)  \\\n",
       "0  [1.0, 0.9333333333333333, 0.9333333333333333, ...          0.000   \n",
       "\n",
       "  Precision(test) Recalll(test) F1_score(test)  \\\n",
       "0           0.000         0.000          0.000   \n",
       "\n",
       "                                   Specificity(test)  \n",
       "0  [1.0, 0.9333333333333333, 0.9333333333333333, ...  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_train=format(accuracy_score(dt_clf.predict(x_train2), y_train1),'.3f')\n",
    "precision_train=format(precision_score(y_train1, dt_clf.predict(x_train2), average='macro'),'.3f')\n",
    "recall_train=format(recall_score(y_train1, dt_clf.predict(x_train2), average='macro'),'.3f')\n",
    "f1_train=format(f1_score(y_train1, dt_clf.predict(x_train2), average='macro'),'.3f')\n",
    "\n",
    "y_pred = dt_clf.predict(x_train2)\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "y_train = np.argmax(y_train1, axis=1)\n",
    "\n",
    "# y_test_pred = model.predict(x_test1)\n",
    "# y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "# y_test = np.argmax(y_test1, axis=1)\n",
    "\n",
    "\n",
    "cnf_matrix_train = confusion_matrix(y_pred, y_train)\n",
    "print(\"Confusion Matrix of DT train:\\n\")\n",
    "print(cnf_matrix_train)\n",
    "# print(cnf_matrix_train)\n",
    "\n",
    "FP = cnf_matrix_train.sum(axis=0) - np.diag(cnf_matrix_train) \n",
    "FN = cnf_matrix_train.sum(axis=1) - np.diag(cnf_matrix_train)\n",
    "TP = np.diag(cnf_matrix_train)\n",
    "TN = cnf_matrix_train.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP)\n",
    "# specificity = tn / (tn+fp)\n",
    "specificity_train = TNR\n",
    "\n",
    "\n",
    "acc_test=format(accuracy_score(dt_clf.predict(x_test2), y_test1),'.3f')\n",
    "precision_test=format(precision_score(y_test1, dt_clf.predict(x_test2), average='macro'),'.3f')\n",
    "recall_test=format(recall_score(y_test1, dt_clf.predict(x_test2), average='macro'),'.3f')\n",
    "f1_test=format(f1_score(y_test1, dt_clf.predict(x_test2), average='macro'),'.3f')\n",
    "\n",
    "# y_pred = clf.predict(x_train2)\n",
    "# y_pred = np.argmax(y_pred, axis=1)\n",
    "# y_train = np.argmax(y_train1, axis=1)\n",
    "\n",
    "y_test_pred = dt_clf.predict(x_test2)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "y_test = np.argmax(y_test1, axis=1)\n",
    "\n",
    "\n",
    "cnf_matrix_test = confusion_matrix(y_test_pred, y_test)\n",
    "print(\"Confusion Matrix of DT test:\\n\")\n",
    "print(cnf_matrix_test)\n",
    "# print(cnf_matrix_train)\n",
    "\n",
    "FP = cnf_matrix_test.sum(axis=0) - np.diag(cnf_matrix_test) \n",
    "FN = cnf_matrix_test.sum(axis=1) - np.diag(cnf_matrix_test)\n",
    "TP = np.diag(cnf_matrix_test)\n",
    "TN = cnf_matrix_test.sum() - (FP + FN + TP)\n",
    "\n",
    "FP = FP.astype(float)\n",
    "FN = FN.astype(float)\n",
    "TP = TP.astype(float)\n",
    "TN = TN.astype(float)\n",
    "\n",
    "# Sensitivity, hit rate, recall, or true positive rate\n",
    "TPR = TP/(TP+FN)\n",
    "# Specificity or true negative rate\n",
    "TNR = TN/(TN+FP)\n",
    "# specificity = tn / (tn+fp)\n",
    "specificity_test = TNR\n",
    "\n",
    "evaluation = pd.DataFrame({'Model': [],\n",
    "                           'Accuracy(train)':[],\n",
    "                           'Precision(train)':[],\n",
    "                           'Recall(train)':[],\n",
    "                           'F1_score(train)':[],\n",
    "                           'Specificity(train)':[],\n",
    "                           'Accuracy(test)':[],\n",
    "                           'Precision(test)':[],\n",
    "                           'Recalll(test)':[],\n",
    "                           'F1_score(test)':[],\n",
    "                           'Specificity(test)':[],\n",
    "                          })\n",
    "\n",
    "r = evaluation.shape[0]\n",
    "evaluation.loc[r] = ['DT',acc_train,precision_train,recall_train,f1_train,specificity_train,acc_test,precision_test,recall_test,f1_test,specificity_test]\n",
    "evaluation.sort_values(by = 'Accuracy(test)', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "signature_fraud_01.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
